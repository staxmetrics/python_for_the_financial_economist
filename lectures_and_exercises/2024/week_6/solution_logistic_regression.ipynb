{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5729489a",
   "metadata": {},
   "source": [
    "# MLE of logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0c4e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'C:\\\\code\\\\python_for_the_financial_economist\\\\')\n",
    "\n",
    "# import relevant packages\n",
    "import numpy as np\n",
    "\n",
    "# packages for convex optimization\n",
    "import cvxpy as cp\n",
    "\n",
    "# for calculating evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from codelib.visualization.layout import DefaultStyle\n",
    "DefaultStyle();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b1bfca-6cb1-4c35-aa37-b44e034852aa",
   "metadata": {},
   "source": [
    "The logistic regression model specifies the probability that a binary outcome variable $y$ equal 1 as \n",
    "\n",
    "$$\n",
    "P(y=1 \\vert \\mathbf{x}) = \\frac{1}{1 + e^{-\\mathbf{x}^\\top \\boldsymbol{\\beta}}}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\beta}$ is the vector of coefficients to be estimated. \n",
    "\n",
    "Below we simulate data from a logistic model with two explanatory variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58ae953f-80df-4e04-bc96-d23e68dd5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# number of simulations\n",
    "num_sim = 100\n",
    "\n",
    "# coefficients\n",
    "beta0 = -1.0\n",
    "beta1 = 2.0\n",
    "beta2 =  -3.0\n",
    "\n",
    "# generate explanatory variables\n",
    "x1 = np.random.normal(loc=0, scale=1, size=num_sim)\n",
    "x2 = np.random.normal(loc=0, scale=1, size=num_sim)\n",
    "\n",
    "# generate probabilties\n",
    "probs = 1 / (1 + np.exp(-(beta0 + beta1 * x1 + beta2 * x2)))\n",
    "\n",
    "# simulate y values\n",
    "y = np.random.binomial(1, probs, size=num_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e098073-5124-47f5-b332-5cfa2d07b0dd",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "The log-likelihood function is given by\n",
    "\n",
    "$$\n",
    "\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^N [y_i \\log \\frac{1}{1 + e^{-\\mathbf{x}^\\top \\boldsymbol{\\beta}}} + (1 - y_i) \\log (1 - \\frac{1}{1 + e^{-\\mathbf{x}^\\top \\boldsymbol{\\beta}}})]\n",
    "$$\n",
    "\n",
    "which is a convex function in $\\boldsymbol{\\beta}$.\n",
    "\n",
    "Use the `CVXPY` package to estimate the coefficients by maximizing the log-likelihood function. \n",
    "\n",
    "### Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e9729d8-d3af-4837-9626-e01f8a15d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.30648337, -4.33761439])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solving with CVXPY\n",
    "\"\"\"\n",
    "\n",
    "x_mat = np.vstack((x1, x2)).T\n",
    "\n",
    "# define optimization variables\n",
    "beta = cp.Variable(2)\n",
    "intercept = cp.Variable()\n",
    "\n",
    "# define objective\n",
    "log_likelihood = cp.sum(cp.multiply(y, x_mat @ beta + intercept) - cp.logistic(x_mat @ beta + intercept))\n",
    "objective = cp.Maximize(log_likelihood)\n",
    "\n",
    "# define problem \n",
    "problem = cp.Problem(objective)\n",
    "\n",
    "# solve problem\n",
    "problem.solve()\n",
    "\n",
    "# solution \n",
    "beta_est = beta.value # <- gives the same solution as the analytical formula\n",
    "beta_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e862738e-958e-47b9-a004-039774fdd2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-1.47862693)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "intercept_est = intercept.value\n",
    "intercept_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca35b5-26f2-4ff0-ae68-f1cb059188f1",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Calculate the predicted probabilities. Classify $y$ based on a  50% threshold. In addition calculate the accuracy score and the confusion matrix (use metrics.accuracy_score and metrics.confusion_matrix from `scikit-learn`).\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5a8bee9-b158-44f2-87bc-2d527cff9488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.88\n",
      "Confusion Matrix:\n",
      "[[57  4]\n",
      " [ 8 31]]\n"
     ]
    }
   ],
   "source": [
    "probs_pred = 1 / (1 + np.exp(- (x_mat @ beta_est + intercept_est)))\n",
    "\n",
    "# Classify based on a threshold (e.g., 0.5)\n",
    "y_pred = (probs_pred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd140c-edd8-4daf-90c2-763f3486246c",
   "metadata": {},
   "source": [
    "The accuracy score is the fraction of correct predictions. \n",
    "\n",
    "We interpret the confusion matrix as follows\n",
    "\n",
    "<table><tbody>\r\n",
    "  <tr>\r\n",
    "    <td>True Negative</td>\r\n",
    "    <td>False Positive</td>\r\n",
    "  </tr>\r\n",
    "  <tr>\r\n",
    "    <td>False Negative</td>\r\n",
    "    <td>True Positive</td>\r\n",
    "  </tr>\r\n",
    "</tbody>\r\n",
    "</table>  </tr>\r\n",
    "</tbody>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a4885-573e-421b-8c76-ce506c65def5",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "To be able to perform variable selection, we can add an L1 penalty to the log-likelihood\n",
    "\n",
    "$$\n",
    "\\ell_{reg}(\\boldsymbol{\\beta}) = \\ell(\\boldsymbol{\\beta}) - \\lambda \\Vert \\boldsymbol{\\beta} \\Vert_1 , \\; \\; \\lambda > 0\n",
    "$$\n",
    "\n",
    "Again, estimate the parameters using `CVXPY` and evaluate the model. \n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a862435a-4821-4bf8-be4d-2e68da09edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.4772392, -2.2053723])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solving with CVXPY\n",
    "\"\"\"\n",
    "\n",
    "lambda_reg = cp.Parameter(nonneg=True)\n",
    "lambda_reg.value = 3 # you can change this parameter to change the regularization \n",
    "\n",
    "# define optimization variables\n",
    "beta = cp.Variable(2)\n",
    "intercept = cp.Variable()\n",
    "\n",
    "# define objective\n",
    "log_likelihood = cp.sum(cp.multiply(y, x_mat @ beta + intercept) - cp.logistic(x_mat @ beta + intercept)) - lambda_reg * cp.norm1(beta)\n",
    "objective = cp.Maximize(log_likelihood)\n",
    "\n",
    "# define problem \n",
    "problem = cp.Problem(objective)\n",
    "\n",
    "# solve problem\n",
    "problem.solve()\n",
    "\n",
    "# solution \n",
    "beta_reg_est = beta.value # <- gives the same solution as the analytical formula\n",
    "beta_reg_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a3c6455-0021-4e41-8ffd-dacb8a6af74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-0.80438246)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "intercept_reg_est = intercept.value\n",
    "intercept_reg_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edecf842-d4e0-4a67-af3c-255cc341a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[58  3]\n",
      " [ 7 32]]\n"
     ]
    }
   ],
   "source": [
    "probs_pred = 1 / (1 + np.exp(- (x_mat @ beta_reg_est + intercept_reg_est)))\n",
    "\n",
    "# Classify based on a threshold (e.g., 0.5)\n",
    "y_pred = (probs_pred >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779288fe-5417-466a-b57e-7d3c02df40e5",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "Logistic regression model with maximum likelihood: [Statlect.com](https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
